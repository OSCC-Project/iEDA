/*******************************************************************************
 * MIT License
 *
 * This file is part of Mt-KaHyPar.
 *
 * Copyright (C) 2021 Tobias Heuer <tobias.heuer@kit.edu>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 ******************************************************************************/


#include "mt-kahypar/partition/refinement/flows/problem_construction.h"

#include <unordered_map>

#include "tbb/parallel_for.h"

#include "mt-kahypar/definitions.h"
#include "mt-kahypar/partition/mapping/target_graph.h"

namespace mt_kahypar {

template<typename TypeTraits>
void ProblemConstruction<TypeTraits>::BFSData::clearQueue() {
  while ( !queue.empty() ) queue.pop();
  while ( !next_queue.empty() ) next_queue.pop();
}

template<typename TypeTraits>
void ProblemConstruction<TypeTraits>::BFSData::reset() {
  current_distance = 0;
  queue_weight_block_0 = 0;
  queue_weight_block_1 = 0;
  lock_queue = false;
  clearQueue();
  std::fill(visited_hn.begin(), visited_hn.end(), false);
  std::fill(visited_he.begin(), visited_he.end(), false);
  std::fill(contained_hes.begin(), contained_hes.end(), false);
  std::fill(locked_blocks.begin(), locked_blocks.end(), false);
}

template<typename TypeTraits>
HypernodeID ProblemConstruction<TypeTraits>::BFSData::pop_hypernode() {
  ASSERT(!queue.empty());
  const HypernodeID hn = queue.front();
  queue.pop();
  return hn;
}

template<typename TypeTraits>
void ProblemConstruction<TypeTraits>::BFSData::add_pins_of_hyperedge_to_queue(
  const HyperedgeID& he,
  const PartitionedHypergraph& phg,
  const size_t max_bfs_distance,
  const HypernodeWeight max_weight_block_0,
  const HypernodeWeight max_weight_block_1) {
  if ( current_distance <= max_bfs_distance && !lock_queue ) {
    if ( !visited_he[he] ) {
      for ( const HypernodeID& pin : phg.pins(he) ) {
        if ( !visited_hn[pin] ) {
          const PartitionID block = phg.partID(pin);
          const bool is_block_0 = blocks.i == block;
          const bool is_block_1 = blocks.j == block;
          if ( (is_block_0 || is_block_1) && !locked_blocks[block] ) {
            next_queue.push(pin);
            queue_weight_block_0 += is_block_0 ? phg.nodeWeight(pin) : 0;
            queue_weight_block_1 += is_block_1 ? phg.nodeWeight(pin) : 0;
          }
          visited_hn[pin] = true;
        }
      }
      visited_he[he] = true;
    }
  }

  if ( queue_weight_block_0 >= max_weight_block_0 &&
       queue_weight_block_1 >= max_weight_block_1 ) {
    lock_queue = true;
  }
}

namespace {
  using assert_map = std::unordered_map<HyperedgeID, bool>;
}

template<typename TypeTraits>
Subhypergraph ProblemConstruction<TypeTraits>::construct(const SearchID search_id,
                                                         QuotientGraph<TypeTraits>& quotient_graph,
                                                         const PartitionedHypergraph& phg) {
  Subhypergraph sub_hg;
  BFSData& bfs = _local_bfs.local();
  bfs.reset();
  bfs.blocks = quotient_graph.getBlockPair(search_id);
  sub_hg.block_0 = bfs.blocks.i;
  sub_hg.block_1 = bfs.blocks.j;
  sub_hg.weight_of_block_0 = 0;
  sub_hg.weight_of_block_1 = 0;
  sub_hg.num_pins = 0;
  const HypernodeWeight max_weight_block_0 =
    _scaling * _context.partition.perfect_balance_part_weights[sub_hg.block_1] - phg.partWeight(sub_hg.block_1);
  const HypernodeWeight max_weight_block_1 =
    _scaling * _context.partition.perfect_balance_part_weights[sub_hg.block_0] - phg.partWeight(sub_hg.block_0);
  const size_t max_bfs_distance = _context.refinement.flows.max_bfs_distance;


  // We initialize the BFS with all cut hyperedges running
  // between the involved block associated with the search
  bfs.clearQueue();
  quotient_graph.doForAllCutHyperedgesOfSearch(search_id, [&](const HyperedgeID& he) {
    bfs.add_pins_of_hyperedge_to_queue(he, phg, max_bfs_distance,
      max_weight_block_0, max_weight_block_1);
  });
  bfs.swap_with_next_queue();

  // BFS
  while ( !bfs.is_empty() &&
          !isMaximumProblemSizeReached(sub_hg,
            max_weight_block_0, max_weight_block_1, bfs.locked_blocks) ) {
    HypernodeID hn = bfs.pop_hypernode();
    PartitionID block = phg.partID(hn);
    const bool is_block_contained = block == sub_hg.block_0 || block == sub_hg.block_1;
    if ( is_block_contained && !bfs.locked_blocks[block] ) {
      const bool is_fixed = phg.isFixed(hn);
      // We do not add fixed vertices to the flow problem, but still
      // expand the BFS to its neighbors
      if ( !is_fixed ) {
        if ( sub_hg.block_0  == block ) {
          sub_hg.nodes_of_block_0.push_back(hn);
          sub_hg.weight_of_block_0 += phg.nodeWeight(hn);
        } else {
          ASSERT(sub_hg.block_1 == block);
          sub_hg.nodes_of_block_1.push_back(hn);
          sub_hg.weight_of_block_1 += phg.nodeWeight(hn);
        }
        sub_hg.num_pins += phg.nodeDegree(hn);
      }

      // Push all neighbors of the added vertex into the queue
      for ( const HyperedgeID& he : phg.incidentEdges(hn) ) {
        bfs.add_pins_of_hyperedge_to_queue(he, phg, max_bfs_distance,
          max_weight_block_0, max_weight_block_1);
        if ( !is_fixed && !bfs.contained_hes[phg.uniqueEdgeID(he)] ) {
          sub_hg.hes.push_back(he);
          bfs.contained_hes[phg.uniqueEdgeID(he)] = true;
        }
      }
    }

    if ( bfs.is_empty() ) {
      bfs.swap_with_next_queue();
    }
  }
  DBG << "Search ID:" << search_id << "-" << sub_hg;

  // Check if all touched hyperedges are contained in subhypergraph
  ASSERT([&]() {
    assert_map expected_hes;
    for ( const HyperedgeID& he : sub_hg.hes ) {
      const HyperedgeID id = phg.uniqueEdgeID(he);
      if ( expected_hes.count(id) > 0 ) {
        LOG << "Hyperedge" << he << "is contained multiple times in subhypergraph!";
        return false;
      }
      expected_hes[id] = true;
    }

    for ( const HypernodeID& hn : sub_hg.nodes_of_block_0 ) {
      for ( const HyperedgeID& he : phg.incidentEdges(hn) ) {
        const HyperedgeID id = phg.uniqueEdgeID(he);
        if ( expected_hes.count(id) == 0 ) {
          LOG << "Hyperedge" << he << "not contained in subhypergraph!";
          return false;
        }
        expected_hes[id] = false;
      }
    }

    for ( const HypernodeID& hn : sub_hg.nodes_of_block_1 ) {
      for ( const HyperedgeID& he : phg.incidentEdges(hn) ) {
        const HyperedgeID id = phg.uniqueEdgeID(he);
        if ( expected_hes.count(id) == 0 ) {
          LOG << "Hyperedge" << he << "not contained in subhypergraph!";
          return false;
        }
        expected_hes[id] = false;
      }
    }

    for ( const auto& entry : expected_hes ) {
      const HyperedgeID he = entry.first;
      const bool visited = !entry.second;
      if ( !visited ) {
        LOG << "HyperedgeID" << he << "should be not part of subhypergraph!";
        return false;
      }
    }
    return true;
  }(), "Subhypergraph construction failed!");

  return sub_hg;
}

template<typename TypeTraits>
void ProblemConstruction<TypeTraits>::changeNumberOfBlocks(const PartitionID new_k) {
  ASSERT(new_k == _context.partition.k);
  for ( BFSData& data : _local_bfs ) {
    if ( static_cast<size_t>(new_k) > data.locked_blocks.size() ) {
      data.locked_blocks.assign(new_k, false);
    }
  }
}

template<typename TypeTraits>
MT_KAHYPAR_ATTRIBUTE_ALWAYS_INLINE bool ProblemConstruction<TypeTraits>::isMaximumProblemSizeReached(
  const Subhypergraph& sub_hg,
  const HypernodeWeight max_weight_block_0,
  const HypernodeWeight max_weight_block_1,
  vec<bool>& locked_blocks) const {
  if ( sub_hg.weight_of_block_0 >= max_weight_block_0 ) {
    locked_blocks[sub_hg.block_0] = true;
  }
  if ( sub_hg.weight_of_block_1 >= max_weight_block_1 ) {
    locked_blocks[sub_hg.block_1] = true;
  }
  if ( sub_hg.num_pins >= _context.refinement.flows.max_num_pins ) {
    locked_blocks[sub_hg.block_0] = true;
    locked_blocks[sub_hg.block_1] = true;
  }

  return locked_blocks[sub_hg.block_0] && locked_blocks[sub_hg.block_1];
}

INSTANTIATE_CLASS_WITH_TYPE_TRAITS(ProblemConstruction)

} // namespace mt_kahypar